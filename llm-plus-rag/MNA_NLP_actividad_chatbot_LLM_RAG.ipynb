{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hVND8xY2OKY"
      },
      "source": [
        "# **Procesamiento de Lenguaje Natural**\n",
        "\n",
        "## Maestría en Inteligencia Artificial Aplicada\n",
        "#### Tecnológico de Monterrey\n",
        "#### Prof Luis Eduardo Falcón Morales\n",
        "\n",
        "### **Adtividad en Equipos: sistema LLM + RAG**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aimHVFOv23lm"
      },
      "source": [
        "* **Nombres y matrículas:**\n",
        "\n",
        "  *   Elemento de lista\n",
        "  *   Elemento de lista\n",
        "  *   Elemento de lista\n",
        "\n",
        "* **Número de Equipo:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jimvsiVgjMg"
      },
      "source": [
        "* ##### **El formato de este cuaderno de Jupyter es libre, pero debe incuir al menos las siguientes secciones:**\n",
        "\n",
        "  * ##### **Introducción de la problemática a resolver.**\n",
        "  * ##### **Sistema RAG + LLM**\n",
        "  * ##### **El chatbot, incluyendo ejemplos de prueba.**\n",
        "  * ##### **Conclusiones**\n",
        "\n",
        "* ##### **Pueden importar los paquetes o librerías que requieran.**\n",
        "\n",
        "* ##### **Pueden incluir las celdas y líneas de código que deseen.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup API openAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Leer pdfs usando langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Loaded 500 pages from PDF files.\n",
            "📄 First page preview:\n",
            "\n",
            "THE STATUTES OF THE REPUBLIC OF SINGAPORE\n",
            "PERSONAL DATA PROTECTION\n",
            "ACT 2012\n",
            "2020 REVISED EDITION\n",
            "This revised edition incorporates all amendments up to and\n",
            "including 1 December 2021 and comes into operation on 31 December 2021.\n",
            "Prepared and Published by\n",
            "THE LAW REVISION COMMISSION\n",
            "UNDER THE AUTHORITY OF\n",
            "THE REVISED EDITION OF THE LAWS ACT 1983\n",
            "Informal Consolidation– version in force from 1/10/2022\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from pathlib import Path\n",
        "\n",
        "# Load all PDF files in the `docs/` folder\n",
        "def load_pdfs_from_folder(folder_path):\n",
        "    all_docs = []\n",
        "    for pdf_path in Path(folder_path).glob(\"*.pdf\"):\n",
        "        loader = PyPDFLoader(str(pdf_path))\n",
        "        docs = loader.load()\n",
        "        for doc in docs:\n",
        "            doc.metadata[\"source\"] = pdf_path.name  # Add source metadata\n",
        "        all_docs.extend(docs)\n",
        "    return all_docs\n",
        "\n",
        "documents = load_pdfs_from_folder(\"docs/\")\n",
        "print(f\"✅ Loaded {len(documents)} pages from PDF files.\")\n",
        "print(f\"📄 First page preview:\\n\\n{documents[0].page_content[:500]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Separación de los documentos en chunks para el embedding y vector store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Split into 1887 chunks.\n",
            "📄 First chunk preview:\n",
            "\n",
            "THE STATUTES OF THE REPUBLIC OF SINGAPORE\n",
            "PERSONAL DATA PROTECTION\n",
            "ACT 2012\n",
            "2020 REVISED EDITION\n",
            "This revised edition incorporates all amendments up to and\n",
            "including 1 December 2021 and comes into operation on 31 December 2021.\n",
            "Prepared and Published by\n",
            "THE LAW REVISION COMMISSION\n",
            "UNDER THE AUTHORITY OF\n",
            "THE REVISED EDITION OF THE LAWS ACT 1983\n",
            "Informal Consolidation– version in force from 1/10/2022\n"
          ]
        }
      ],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Recommended for OpenAI embeddings: 1000 characters with 200 overlap\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
        ")\n",
        "\n",
        "# Apply to your loaded documents\n",
        "chunks = text_splitter.split_documents(documents)\n",
        "\n",
        "print(f\"✅ Split into {len(chunks)} chunks.\")\n",
        "print(f\"📄 First chunk preview:\\n\\n{chunks[0].page_content[:500]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Embeddding y creación del vector store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Loaded existing Chroma DB.\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "\n",
        "# 1. Define embedding model\n",
        "embedding_function = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "# 2. Set path to local DB\n",
        "persist_directory = \"chroma_db\"\n",
        "\n",
        "# 3. Try to load existing DB; if not, create from chunks\n",
        "try:\n",
        "    vectorstore = Chroma(\n",
        "        embedding_function=embedding_function,\n",
        "        persist_directory=persist_directory\n",
        "    )\n",
        "    print(\"✅ Loaded existing Chroma DB.\")\n",
        "except:\n",
        "    print(\"🚧 Creating new vector store...\")\n",
        "    vectorstore = Chroma.from_documents(\n",
        "        documents=chunks,\n",
        "        embedding=embedding_function,\n",
        "        persist_directory=persist_directory\n",
        "    )\n",
        "    print(\"✅ New Chroma DB created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RAG + LLM "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🧠 Answer:\n",
            " The legal bases for processing personal data under the GDPR are as follows:\n",
            "\n",
            "1. **Consent**: The data subject has given clear consent for their personal data to be processed for a specific purpose.\n",
            "2. **Contractual necessity**: Processing is necessary for the performance of a contract to which the data subject is a party, or to take steps at the request of the data subject prior to entering into a contract.\n",
            "3. **Legal obligation**: Processing is necessary for compliance with a legal obligation to which the controller is subject.\n",
            "4. **Vital interests**: Processing is necessary to protect the vital interests of the data subject or another natural person.\n",
            "5. **Public task**: Processing is necessary for the performance of a task carried out in the public interest or in the exercise of official authority vested in the controller.\n",
            "6. **Legitimate interests**: Processing is necessary for the purposes of legitimate interests pursued by the controller or a third party, except where such interests are overridden by the interests or fundamental rights and freedoms of the data subject.\n",
            "\n",
            "📄 Source: europe.pdf\n",
            "---\n",
            "initially collect ed. In such a case, no lega l basis separate from that whic h allo wed the collection of the personal \n",
            "data is required. If the processing is necessar y f or the performa nce of a task car r ied out in the public inte rest or \n",
            "in the exer cise of off icial author ity vested in the \n",
            "\n",
            "📄 Source: brazil.pdf\n",
            "---\n",
            "CHAPTER II \n",
            "PROCESSING OF PERSONAL DATA \n",
            "Section I \n",
            "Requirements for the Processing of Personal Data \n",
            " \n",
            " \n",
            "Art. 7 Processing of personal data shall only be carried out under the following \n",
            "circumstances: \n",
            "I  – with the consent of the data subject; \n",
            "II   – for compliance with a legal or regulatory obl\n",
            "\n",
            "📄 Source: europe.pdf\n",
            "---\n",
            "controller where personal data are processed in circumstances where data subjects do not reasonably expect \n",
            "fur ther processing. Given that it is f or the legislator to pro vide by law f or the legal basis f or public author ities to \n",
            "process personal data, that legal basis should not apply to the p\n",
            "\n",
            "📄 Source: europe.pdf\n",
            "---\n",
            "processing of personal data concer ning him or her which is based on point (e) or (f) of Ar ticle 6(1), including prof iling \n",
            "based on those pro visions. The controller shall no long er process the personal data unless the controller demonstrates \n",
            "compelling legitimate grounds f or the processing wh\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# 1. Set up the LLM with gpt-4o-mini\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
        "\n",
        "# 2. Create a retriever from your Chroma vector store\n",
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})\n",
        "\n",
        "# 3. Build the Retrieval-Augmented Generation chain\n",
        "rag_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True  # So we can display sources\n",
        ")\n",
        "\n",
        "# 4. Test it!\n",
        "query = \"What are the legal bases for processing personal data under the GDPR?\"\n",
        "response = rag_chain.invoke(query)\n",
        "\n",
        "# Show answer\n",
        "print(\"🧠 Answer:\\n\", response[\"result\"])\n",
        "\n",
        "# Show sources\n",
        "for doc in response[\"source_documents\"]:\n",
        "    print(f\"\\n📄 Source: {doc.metadata['source']}\\n---\\n{doc.page_content[:300]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Comparando RAG + LLM contra un LLM sin RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚫 No RAG Answer:\n",
            " Yes, the General Data Protection Regulation (GDPR) allows for the processing of personal data without consent under certain circumstances. While consent is one of the legal bases for processing personal data, the GDPR outlines several other legal bases that can justify processing without the need for explicit consent. These include:\n",
            "\n",
            "1. **Contractual Necessity**: Processing is necessary for the performance of a contract to which the data subject is a party or to take steps at the request of the data subject prior to entering into a contract.\n",
            "\n",
            "2. **Legal Obligation**: Processing is necessary for compliance with a legal obligation to which the data controller is subject.\n",
            "\n",
            "3. **Vital Interests**: Processing is necessary to protect the vital interests of the data subject or another natural person.\n",
            "\n",
            "4. **Public Task**: Processing is necessary for the performance of a task carried out in the public interest or in the exercise of official authority vested in the data controller.\n",
            "\n",
            "5. **Legitimate Interests**: Processing is necessary for the purposes of legitimate interests pursued by the data controller or a third party, except where such interests are overridden by the interests or fundamental rights and freedoms of the data subject.\n",
            "\n",
            "Each of these bases has specific requirements and conditions that must be met, and organizations must carefully assess which legal basis applies to their data processing activities.\n",
            "✅ RAG Answer:\n",
            " Yes, the GDPR allows processing without consent under certain conditions. For example, processing can occur if it is necessary for the performance of a contract, compliance with a legal obligation, protection of vital interests, performance of a task carried out in the public interest, or legitimate interests pursued by the data controller or a third party, provided that these interests are not overridden by the interests or fundamental rights and freedoms of the data subject.\n"
          ]
        }
      ],
      "source": [
        "query = \"Does the GDPR allow processing without consent?\"\n",
        "\n",
        "# Without RAG (no context)\n",
        "no_rag_response = llm.invoke(query)\n",
        "print(\"🚫 No RAG Answer:\\n\", no_rag_response.content)\n",
        "\n",
        "# With RAG\n",
        "rag_response = rag_chain.invoke(query)\n",
        "print(\"✅ RAG Answer:\\n\", rag_response[\"result\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| Métrica                        | ❌ Respuesta sin RAG                      | ✅ Respuesta con RAG                     |\n",
        "| ------------------------------ | ---------------------------------------- | --------------------------------------- |\n",
        "| **Precisión factual**          | ✅ Correcta                               | ✅ Correcta                              |\n",
        "| **Claridad**                   | ⚠️ Densa, extensa                        | ✅ Clara y concisa                       |\n",
        "| **Redundancia**                | ❌ Repite definiciones generales          | ✅ Resumen enfocado                      |\n",
        "| **Fundamentación en contexto** | ❌ El LLM se basa en conocimiento general | ✅ Se basa en el documento real del GDPR |\n",
        "| **Estilo**                     | 🗨️ Respuesta tipo conferencia           | ✅ Tono de asistente legal               |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Usando gradio para crear el chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/eahumada/Projects/mna/natural-language-processing/env/lib64/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "# RAG function to connect UI to the model\n",
        "def ask_data_law(query):\n",
        "    if not query.strip():\n",
        "        return \"Please enter a valid question.\"\n",
        "    \n",
        "    response = rag_chain.invoke(query)\n",
        "    answer = response[\"result\"]\n",
        "\n",
        "    # Optional: show sources (for transparency)\n",
        "    sources = \"\\n\\n\".join(\n",
        "        f\"📄 {doc.metadata['source']}\" for doc in response[\"source_documents\"]\n",
        "    )\n",
        "    \n",
        "    return f\"🧠 **Answer:**\\n{answer}\\n\\n---\\n**Sources:**\\n{sources}\"\n",
        "\n",
        "# Gradio Blocks interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# 💼 Ask the Data Law Assistant\")\n",
        "    gr.Markdown(\"Ask about GDPR, CCPA, LGPD, APPI, and more.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        textbox = gr.Textbox(label=\"Your Question\")\n",
        "        submit_btn = gr.Button(\"Ask\")\n",
        "\n",
        "    output = gr.Markdown()\n",
        "\n",
        "    submit_btn.click(fn=ask_data_law, inputs=textbox, outputs=output)\n",
        "\n",
        "# Launch the app inline\n",
        "demo.launch(inline=True, share=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx-dZSFJz9cK"
      },
      "source": [
        "# **Conclusiones:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w3usdaC0BCj"
      },
      "source": [
        "* #### **Incluyan sus conclusiones de la actividad chatbot LLM + RAG:**\n",
        "\n",
        "\n",
        "\n",
        "None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtB5Q3m41YQ0"
      },
      "source": [
        "# **Fin de la actividad chatbot: LLM + RAG**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
